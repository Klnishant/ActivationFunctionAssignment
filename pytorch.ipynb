{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOzSIyiY121VxIFKlAsjtyj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Klnishant/ActivationFunctionAssignment/blob/main/pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n1az7UcMeA6a"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.tensor(4.)\n",
        "t1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYu1OcrOeQeJ",
        "outputId": "473e63c3-14a4-4156-c401-91e21ed1d6cb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qx5gMTked_Y",
        "outputId": "4410d98d-d9c8-4466-ed4f-f7163df6be17"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2=torch.tensor([4.,5,6,7])\n",
        "t2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ru_k1XSffP_2",
        "outputId": "df5293c0-c39b-458c-ff04-f6bb3f9f1b1a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4., 5., 6., 7.])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t3 = torch.tensor([[1.,2],\n",
        "                   [3,4],\n",
        "                   [5,6]])\n",
        "t3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLxero3afYc-",
        "outputId": "a6e335b2-2e7b-4416-d75c-197833117645"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.],\n",
              "        [5., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t1.shape)\n",
        "print(t2.shape)\n",
        "print(t3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOWnl6vvforh",
        "outputId": "acf00644-595d-4e39-f01c-508899e1c5ea"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([])\n",
            "torch.Size([4])\n",
            "torch.Size([3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.tensor(3.)\n",
        "w=torch.tensor(4.,requires_grad=True)\n",
        "b=torch.tensor(5.,requires_grad=True)\n",
        "\n",
        "x,w,b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTxv7CeEf7Th",
        "outputId": "283fd9c1-60b8-41e0-a6e9-452b5ca741d7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(3.), tensor(4., requires_grad=True), tensor(5., requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=w*x+b\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLbIlDm-gdw-",
        "outputId": "fb95e6ff-0674-4eb7-9fee-06a2f8b9aed4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(17., grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()"
      ],
      "metadata": {
        "id": "be3w8HANgxO2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"dy/dx:\",x.grad)\n",
        "print(\"dy/dw:\",w.grad)\n",
        "print(\"dy/db:\",b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_MqvTY6jkeQ",
        "outputId": "b8baa738-d448-45ee-881e-9974bcb9f564"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dy/dx: None\n",
            "dy/dw: tensor(3.)\n",
            "dy/db: tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t6 = torch.full((3,2),42)\n",
        "t6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvXAXujgj__t",
        "outputId": "52ab8f92-058e-4d70-d876-4b5227890bed"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[42, 42],\n",
              "        [42, 42],\n",
              "        [42, 42]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t7 = torch.cat((t3,t6))\n",
        "t7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Yjb5ATbkloo",
        "outputId": "e6890388-202e-4142-a440-286d3eea7e0d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.,  2.],\n",
              "        [ 3.,  4.],\n",
              "        [ 5.,  6.],\n",
              "        [42., 42.],\n",
              "        [42., 42.],\n",
              "        [42., 42.]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t8 = torch.sin((t7))\n",
        "t8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgfpK0Enksrx",
        "outputId": "cfc68b5d-2bee-46f3-cd16-4f535c4571af"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.8415,  0.9093],\n",
              "        [ 0.1411, -0.7568],\n",
              "        [-0.9589, -0.2794],\n",
              "        [-0.9165, -0.9165],\n",
              "        [-0.9165, -0.9165],\n",
              "        [-0.9165, -0.9165]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t9 = t8.reshape((3,2,2))\n",
        "t9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e9lrYPxlAVS",
        "outputId": "cad3786a-35a7-4cfb-e873-5758ff4e6b11"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.8415,  0.9093],\n",
              "         [ 0.1411, -0.7568]],\n",
              "\n",
              "        [[-0.9589, -0.2794],\n",
              "         [-0.9165, -0.9165]],\n",
              "\n",
              "        [[-0.9165, -0.9165],\n",
              "         [-0.9165, -0.9165]]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "_DsQHAHvlRMn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.array([[1,2],[3,4]])\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3HeYwdcloGu",
        "outputId": "dc9440c1-e6a2-421c-8b49-b0d65aa02163"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=torch.from_numpy(x)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zqz8nUELlxeX",
        "outputId": "e38301b2-4fb7-41f0-ddf0-6f2f85a5f7cb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.dtype,y.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCpW_9jZmClI",
        "outputId": "4957b37e-05f9-43b7-ad8c-f53475e8d786"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dtype('int64'), torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z=y.numpy()\n",
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xv72L0IRmIDJ",
        "outputId": "76b6d74d-8dae-4435-99fc-88d220f1a0a8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')"
      ],
      "metadata": {
        "id": "P6qgWpSfmM-y"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = np.array([[56, 70],\n",
        "                    [81, 101],\n",
        "                    [119, 133],\n",
        "                    [22, 37],\n",
        "                    [103, 119]], dtype='float32')"
      ],
      "metadata": {
        "id": "6nGMa4nRm0L8"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.from_numpy(inputs)\n",
        "target=torch.from_numpy(target)\n",
        "\n",
        "print(inputs,\"\\n\")\n",
        "print(target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLIiaMXum518",
        "outputId": "ee2a12ba-88aa-4783-f34d-eef385cf6706"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]]) \n",
            "\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w=torch.randn((2,3),requires_grad=True)\n",
        "b=torch.randn((2,),requires_grad=True)\n",
        "\n",
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMKO_LZWnW-_",
        "outputId": "64dddba9-e843-4e3e-a8d3-6a321e3a3ec4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0472,  0.6283,  1.3675],\n",
            "        [ 0.0493, -1.2936, -0.3631]], requires_grad=True)\n",
            "tensor([ 0.6936, -0.9559], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model(x):\n",
        "  return x @ w.t() + b"
      ],
      "metadata": {
        "id": "FG3DgamSocA2"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(inputs)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blpXyuFlouKY",
        "outputId": "f5f456d0-feb2-47d0-ee76-278ca2b3054d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 105.0339,  -99.6419],\n",
            "        [ 147.7939, -133.5456],\n",
            "        [ 168.3027, -191.0677],\n",
            "        [  83.1175,  -64.9884],\n",
            "        [ 159.9875, -147.1572]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cw2ZWBmso2WJ",
        "outputId": "9912d8a4-5211-42da-abc1-c045ddf57682"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def MSE(actual,target):\n",
        "  diff=actual-target\n",
        "  return torch.sum(diff*diff)/diff.numel()"
      ],
      "metadata": {
        "id": "Ux3qKDbKo5Ji"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = MSE(target,preds)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLXDMQtXp0V3",
        "outputId": "2b402a3f-615b-44c7-d832-4211e0246cf3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(28633.0586, grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()"
      ],
      "metadata": {
        "id": "l74rRgVIp8Zf"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w,\"\\n\")\n",
        "print(w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eabmvRGNqGbZ",
        "outputId": "557d454d-3a6f-481c-a760-0bad961bb892"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0472,  0.6283,  1.3675],\n",
            "        [ 0.0493, -1.2936, -0.3631]], requires_grad=True) \n",
            "\n",
            "tensor([[  4822.6333,   4773.7080,   3098.6582],\n",
            "        [-18137.8125, -21073.5352, -12701.2041]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(b,\"\\n\")\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCKTpyJzqMN5",
        "outputId": "6ace4d7e-e902-4f38-caa0-c7c6ba64b65f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.6936, -0.9559], requires_grad=True) \n",
            "\n",
            "tensor([  56.6471, -219.2802])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w.grad.zero_()\n",
        "b.grad.zero_()\n",
        "\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCMctqGZqS1a",
        "outputId": "e5dbc938-3a37-4af2-837e-94785dd6136c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds=model(inputs)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_N1FoW35qvYc",
        "outputId": "7075cf34-1257-4076-9256-82cdc56e71c6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 105.0339,  -99.6419],\n",
            "        [ 147.7939, -133.5456],\n",
            "        [ 168.3027, -191.0677],\n",
            "        [  83.1175,  -64.9884],\n",
            "        [ 159.9875, -147.1572]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = MSE(target,preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBOFjnTUq8b-",
        "outputId": "a36b1a06-556c-49ec-a3fc-e67590ef717e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(28633.0586, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "\n",
        "print(w.grad,\"\\n\")\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKuuWyvbrEJf",
        "outputId": "acac5931-03b9-498a-b54a-858aa48fdd06"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  4822.6333,   4773.7080,   3098.6582],\n",
            "        [-18137.8125, -21073.5352, -12701.2041]]) \n",
            "\n",
            "tensor([  56.6471, -219.2802])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  w -= w.grad*1e-5\n",
        "  b -= b.grad*1e-5\n",
        "  w.grad.zero_()\n",
        "  b.grad.zero_()"
      ],
      "metadata": {
        "id": "PIlFjlZHrtyz"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wG6IpxxsME1",
        "outputId": "dffc42f2-0734-4bd8-ebc1-2e2abfce67af"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.0631e-03,  5.8057e-01,  1.3365e+00],\n",
            "        [ 2.3066e-01, -1.0828e+00, -2.3613e-01]], requires_grad=True)\n",
            "tensor([ 0.6930, -0.9538], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds=model(inputs)\n",
        "loss=MSE(target,preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuN0SqBasO_e",
        "outputId": "723f1855-e5c0-4188-e635-522ef18827b7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(19617.6250, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(400):\n",
        "  preds=model(inputs)\n",
        "  loss=MSE(target,preds)\n",
        "  loss.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    w -= w.grad*1e-5\n",
        "    b -= b.grad*1e-5\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "\n",
        "  print(f\"epochs:{i/100} and loss:{loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juQtP-Bwslm3",
        "outputId": "8e4bb8a4-8a97-47ef-d079-3bab6b3a66a7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epochs:0.0 and loss:19617.625\n",
            "epochs:0.01 and loss:13538.2861328125\n",
            "epochs:0.02 and loss:9437.587890625\n",
            "epochs:0.03 and loss:6670.31787109375\n",
            "epochs:0.04 and loss:4801.67236328125\n",
            "epochs:0.05 and loss:3538.64599609375\n",
            "epochs:0.06 and loss:2683.78564453125\n",
            "epochs:0.07 and loss:2104.029296875\n",
            "epochs:0.08 and loss:1709.707763671875\n",
            "epochs:0.09 and loss:1440.3935546875\n",
            "epochs:0.1 and loss:1255.3656005859375\n",
            "epochs:0.11 and loss:1127.18115234375\n",
            "epochs:0.12 and loss:1037.3465576171875\n",
            "epochs:0.13 and loss:973.3990478515625\n",
            "epochs:0.14 and loss:926.9390869140625\n",
            "epochs:0.15 and loss:892.30615234375\n",
            "epochs:0.16 and loss:865.6853637695312\n",
            "epochs:0.17 and loss:844.5046997070312\n",
            "epochs:0.18 and loss:827.0311279296875\n",
            "epochs:0.19 and loss:812.0958251953125\n",
            "epochs:0.2 and loss:798.9107055664062\n",
            "epochs:0.21 and loss:786.9442138671875\n",
            "epochs:0.22 and loss:775.8377685546875\n",
            "epochs:0.23 and loss:765.3491821289062\n",
            "epochs:0.24 and loss:755.3145141601562\n",
            "epochs:0.25 and loss:745.623291015625\n",
            "epochs:0.26 and loss:736.2000732421875\n",
            "epochs:0.27 and loss:726.9939575195312\n",
            "epochs:0.28 and loss:717.9700317382812\n",
            "epochs:0.29 and loss:709.104248046875\n",
            "epochs:0.3 and loss:700.3800048828125\n",
            "epochs:0.31 and loss:691.7858276367188\n",
            "epochs:0.32 and loss:683.3131713867188\n",
            "epochs:0.33 and loss:674.9564819335938\n",
            "epochs:0.34 and loss:666.7108154296875\n",
            "epochs:0.35 and loss:658.5728759765625\n",
            "epochs:0.36 and loss:650.5403442382812\n",
            "epochs:0.37 and loss:642.6103515625\n",
            "epochs:0.38 and loss:634.7811889648438\n",
            "epochs:0.39 and loss:627.0513916015625\n",
            "epochs:0.4 and loss:619.4191284179688\n",
            "epochs:0.41 and loss:611.8831787109375\n",
            "epochs:0.42 and loss:604.4420776367188\n",
            "epochs:0.43 and loss:597.0946044921875\n",
            "epochs:0.44 and loss:589.8396606445312\n",
            "epochs:0.45 and loss:582.6757202148438\n",
            "epochs:0.46 and loss:575.6018676757812\n",
            "epochs:0.47 and loss:568.616943359375\n",
            "epochs:0.48 and loss:561.719482421875\n",
            "epochs:0.49 and loss:554.9088134765625\n",
            "epochs:0.5 and loss:548.1834106445312\n",
            "epochs:0.51 and loss:541.5426025390625\n",
            "epochs:0.52 and loss:534.9852294921875\n",
            "epochs:0.53 and loss:528.5100708007812\n",
            "epochs:0.54 and loss:522.1161499023438\n",
            "epochs:0.55 and loss:515.8023681640625\n",
            "epochs:0.56 and loss:509.5679626464844\n",
            "epochs:0.57 and loss:503.41162109375\n",
            "epochs:0.58 and loss:497.3326110839844\n",
            "epochs:0.59 and loss:491.32989501953125\n",
            "epochs:0.6 and loss:485.40234375\n",
            "epochs:0.61 and loss:479.5492248535156\n",
            "epochs:0.62 and loss:473.76953125\n",
            "epochs:0.63 and loss:468.062255859375\n",
            "epochs:0.64 and loss:462.42669677734375\n",
            "epochs:0.65 and loss:456.86163330078125\n",
            "epochs:0.66 and loss:451.36651611328125\n",
            "epochs:0.67 and loss:445.94012451171875\n",
            "epochs:0.68 and loss:440.58184814453125\n",
            "epochs:0.69 and loss:435.2906188964844\n",
            "epochs:0.7 and loss:430.06573486328125\n",
            "epochs:0.71 and loss:424.90655517578125\n",
            "epochs:0.72 and loss:419.8118591308594\n",
            "epochs:0.73 and loss:414.78094482421875\n",
            "epochs:0.74 and loss:409.81317138671875\n",
            "epochs:0.75 and loss:404.907470703125\n",
            "epochs:0.76 and loss:400.06341552734375\n",
            "epochs:0.77 and loss:395.27996826171875\n",
            "epochs:0.78 and loss:390.55645751953125\n",
            "epochs:0.79 and loss:385.8920593261719\n",
            "epochs:0.8 and loss:381.28607177734375\n",
            "epochs:0.81 and loss:376.7377624511719\n",
            "epochs:0.82 and loss:372.24639892578125\n",
            "epochs:0.83 and loss:367.8113708496094\n",
            "epochs:0.84 and loss:363.4317321777344\n",
            "epochs:0.85 and loss:359.10699462890625\n",
            "epochs:0.86 and loss:354.83642578125\n",
            "epochs:0.87 and loss:350.61920166015625\n",
            "epochs:0.88 and loss:346.454833984375\n",
            "epochs:0.89 and loss:342.34246826171875\n",
            "epochs:0.9 and loss:338.2816162109375\n",
            "epochs:0.91 and loss:334.2715759277344\n",
            "epochs:0.92 and loss:330.31170654296875\n",
            "epochs:0.93 and loss:326.4013366699219\n",
            "epochs:0.94 and loss:322.53985595703125\n",
            "epochs:0.95 and loss:318.7267150878906\n",
            "epochs:0.96 and loss:314.9611511230469\n",
            "epochs:0.97 and loss:311.24273681640625\n",
            "epochs:0.98 and loss:307.57080078125\n",
            "epochs:0.99 and loss:303.9447937011719\n",
            "epochs:1.0 and loss:300.3641052246094\n",
            "epochs:1.01 and loss:296.82806396484375\n",
            "epochs:1.02 and loss:293.33636474609375\n",
            "epochs:1.03 and loss:289.88818359375\n",
            "epochs:1.04 and loss:286.4830627441406\n",
            "epochs:1.05 and loss:283.1205139160156\n",
            "epochs:1.06 and loss:279.79998779296875\n",
            "epochs:1.07 and loss:276.5208435058594\n",
            "epochs:1.08 and loss:273.2827453613281\n",
            "epochs:1.09 and loss:270.08502197265625\n",
            "epochs:1.1 and loss:266.92718505859375\n",
            "epochs:1.11 and loss:263.808837890625\n",
            "epochs:1.12 and loss:260.7294006347656\n",
            "epochs:1.13 and loss:257.68841552734375\n",
            "epochs:1.14 and loss:254.68527221679688\n",
            "epochs:1.15 and loss:251.7196502685547\n",
            "epochs:1.16 and loss:248.7909698486328\n",
            "epochs:1.17 and loss:245.89892578125\n",
            "epochs:1.18 and loss:243.04287719726562\n",
            "epochs:1.19 and loss:240.222412109375\n",
            "epochs:1.2 and loss:237.43716430664062\n",
            "epochs:1.21 and loss:234.68667602539062\n",
            "epochs:1.22 and loss:231.9704132080078\n",
            "epochs:1.23 and loss:229.28793334960938\n",
            "epochs:1.24 and loss:226.6389617919922\n",
            "epochs:1.25 and loss:224.02294921875\n",
            "epochs:1.26 and loss:221.43954467773438\n",
            "epochs:1.27 and loss:218.888427734375\n",
            "epochs:1.28 and loss:216.36898803710938\n",
            "epochs:1.29 and loss:213.8807830810547\n",
            "epochs:1.3 and loss:211.4237060546875\n",
            "epochs:1.31 and loss:208.99722290039062\n",
            "epochs:1.32 and loss:206.6008758544922\n",
            "epochs:1.33 and loss:204.23440551757812\n",
            "epochs:1.34 and loss:201.89735412597656\n",
            "epochs:1.35 and loss:199.58935546875\n",
            "epochs:1.36 and loss:197.31005859375\n",
            "epochs:1.37 and loss:195.05911254882812\n",
            "epochs:1.38 and loss:192.836181640625\n",
            "epochs:1.39 and loss:190.64089965820312\n",
            "epochs:1.4 and loss:188.47280883789062\n",
            "epochs:1.41 and loss:186.33168029785156\n",
            "epochs:1.42 and loss:184.21725463867188\n",
            "epochs:1.43 and loss:182.1289825439453\n",
            "epochs:1.44 and loss:180.0666961669922\n",
            "epochs:1.45 and loss:178.03004455566406\n",
            "epochs:1.46 and loss:176.01864624023438\n",
            "epochs:1.47 and loss:174.03225708007812\n",
            "epochs:1.48 and loss:172.07052612304688\n",
            "epochs:1.49 and loss:170.133056640625\n",
            "epochs:1.5 and loss:168.21969604492188\n",
            "epochs:1.51 and loss:166.330078125\n",
            "epochs:1.52 and loss:164.4639129638672\n",
            "epochs:1.53 and loss:162.6208038330078\n",
            "epochs:1.54 and loss:160.80052185058594\n",
            "epochs:1.55 and loss:159.00294494628906\n",
            "epochs:1.56 and loss:157.2275390625\n",
            "epochs:1.57 and loss:155.47413635253906\n",
            "epochs:1.58 and loss:153.7425079345703\n",
            "epochs:1.59 and loss:152.0323028564453\n",
            "epochs:1.6 and loss:150.3432159423828\n",
            "epochs:1.61 and loss:148.67514038085938\n",
            "epochs:1.62 and loss:147.0276336669922\n",
            "epochs:1.63 and loss:145.40054321289062\n",
            "epochs:1.64 and loss:143.79360961914062\n",
            "epochs:1.65 and loss:142.20651245117188\n",
            "epochs:1.66 and loss:140.6390380859375\n",
            "epochs:1.67 and loss:139.09097290039062\n",
            "epochs:1.68 and loss:137.56204223632812\n",
            "epochs:1.69 and loss:136.05198669433594\n",
            "epochs:1.7 and loss:134.56057739257812\n",
            "epochs:1.71 and loss:133.087646484375\n",
            "epochs:1.72 and loss:131.6327667236328\n",
            "epochs:1.73 and loss:130.1959991455078\n",
            "epochs:1.74 and loss:128.77694702148438\n",
            "epochs:1.75 and loss:127.3753433227539\n",
            "epochs:1.76 and loss:125.9910888671875\n",
            "epochs:1.77 and loss:124.6238784790039\n",
            "epochs:1.78 and loss:123.27352142333984\n",
            "epochs:1.79 and loss:121.9398193359375\n",
            "epochs:1.8 and loss:120.62255859375\n",
            "epochs:1.81 and loss:119.321533203125\n",
            "epochs:1.82 and loss:118.0364990234375\n",
            "epochs:1.83 and loss:116.767333984375\n",
            "epochs:1.84 and loss:115.51371765136719\n",
            "epochs:1.85 and loss:114.27558898925781\n",
            "epochs:1.86 and loss:113.05269622802734\n",
            "epochs:1.87 and loss:111.8448486328125\n",
            "epochs:1.88 and loss:110.65189361572266\n",
            "epochs:1.89 and loss:109.4736099243164\n",
            "epochs:1.9 and loss:108.30965423583984\n",
            "epochs:1.91 and loss:107.16017150878906\n",
            "epochs:1.92 and loss:106.02470397949219\n",
            "epochs:1.93 and loss:104.90321350097656\n",
            "epochs:1.94 and loss:103.7955322265625\n",
            "epochs:1.95 and loss:102.701416015625\n",
            "epochs:1.96 and loss:101.6207275390625\n",
            "epochs:1.97 and loss:100.5532455444336\n",
            "epochs:1.98 and loss:99.49893951416016\n",
            "epochs:1.99 and loss:98.45748138427734\n",
            "epochs:2.0 and loss:97.4288558959961\n",
            "epochs:2.01 and loss:96.41275787353516\n",
            "epochs:2.02 and loss:95.4091567993164\n",
            "epochs:2.03 and loss:94.41780853271484\n",
            "epochs:2.04 and loss:93.4386215209961\n",
            "epochs:2.05 and loss:92.47135162353516\n",
            "epochs:2.06 and loss:91.51600646972656\n",
            "epochs:2.07 and loss:90.57225799560547\n",
            "epochs:2.08 and loss:89.64008331298828\n",
            "epochs:2.09 and loss:88.71925354003906\n",
            "epochs:2.1 and loss:87.80973052978516\n",
            "epochs:2.11 and loss:86.91130065917969\n",
            "epochs:2.12 and loss:86.02379608154297\n",
            "epochs:2.13 and loss:85.14715576171875\n",
            "epochs:2.14 and loss:84.28120422363281\n",
            "epochs:2.15 and loss:83.42577362060547\n",
            "epochs:2.16 and loss:82.58077239990234\n",
            "epochs:2.17 and loss:81.74610900878906\n",
            "epochs:2.18 and loss:80.9215316772461\n",
            "epochs:2.19 and loss:80.1070785522461\n",
            "epochs:2.2 and loss:79.30250549316406\n",
            "epochs:2.21 and loss:78.50770568847656\n",
            "epochs:2.22 and loss:77.72261047363281\n",
            "epochs:2.23 and loss:76.94698333740234\n",
            "epochs:2.24 and loss:76.18083190917969\n",
            "epochs:2.25 and loss:75.42396545410156\n",
            "epochs:2.26 and loss:74.67628479003906\n",
            "epochs:2.27 and loss:73.93766784667969\n",
            "epochs:2.28 and loss:73.20806884765625\n",
            "epochs:2.29 and loss:72.48722839355469\n",
            "epochs:2.3 and loss:71.77516174316406\n",
            "epochs:2.31 and loss:71.07172393798828\n",
            "epochs:2.32 and loss:70.37678527832031\n",
            "epochs:2.33 and loss:69.69026947021484\n",
            "epochs:2.34 and loss:69.0120620727539\n",
            "epochs:2.35 and loss:68.34205627441406\n",
            "epochs:2.36 and loss:67.68011474609375\n",
            "epochs:2.37 and loss:67.02616119384766\n",
            "epochs:2.38 and loss:66.38018798828125\n",
            "epochs:2.39 and loss:65.741943359375\n",
            "epochs:2.4 and loss:65.1114273071289\n",
            "epochs:2.41 and loss:64.48847961425781\n",
            "epochs:2.42 and loss:63.873085021972656\n",
            "epochs:2.43 and loss:63.265037536621094\n",
            "epochs:2.44 and loss:62.664344787597656\n",
            "epochs:2.45 and loss:62.0709114074707\n",
            "epochs:2.46 and loss:61.48454666137695\n",
            "epochs:2.47 and loss:60.9052619934082\n",
            "epochs:2.48 and loss:60.33293533325195\n",
            "epochs:2.49 and loss:59.76750564575195\n",
            "epochs:2.5 and loss:59.2088508605957\n",
            "epochs:2.51 and loss:58.6568603515625\n",
            "epochs:2.52 and loss:58.111534118652344\n",
            "epochs:2.53 and loss:57.57269287109375\n",
            "epochs:2.54 and loss:57.04034423828125\n",
            "epochs:2.55 and loss:56.514366149902344\n",
            "epochs:2.56 and loss:55.99467849731445\n",
            "epochs:2.57 and loss:55.481178283691406\n",
            "epochs:2.58 and loss:54.97380447387695\n",
            "epochs:2.59 and loss:54.4725341796875\n",
            "epochs:2.6 and loss:53.97724533081055\n",
            "epochs:2.61 and loss:53.4878044128418\n",
            "epochs:2.62 and loss:53.00422286987305\n",
            "epochs:2.63 and loss:52.52642822265625\n",
            "epochs:2.64 and loss:52.0543327331543\n",
            "epochs:2.65 and loss:51.5877799987793\n",
            "epochs:2.66 and loss:51.1268310546875\n",
            "epochs:2.67 and loss:50.67134475708008\n",
            "epochs:2.68 and loss:50.221275329589844\n",
            "epochs:2.69 and loss:49.77656173706055\n",
            "epochs:2.7 and loss:49.33708190917969\n",
            "epochs:2.71 and loss:48.90285110473633\n",
            "epochs:2.72 and loss:48.4737548828125\n",
            "epochs:2.73 and loss:48.049739837646484\n",
            "epochs:2.74 and loss:47.6307373046875\n",
            "epochs:2.75 and loss:47.21663284301758\n",
            "epochs:2.76 and loss:46.80748748779297\n",
            "epochs:2.77 and loss:46.403175354003906\n",
            "epochs:2.78 and loss:46.003597259521484\n",
            "epochs:2.79 and loss:45.608699798583984\n",
            "epochs:2.8 and loss:45.21849822998047\n",
            "epochs:2.81 and loss:44.8328742980957\n",
            "epochs:2.82 and loss:44.451812744140625\n",
            "epochs:2.83 and loss:44.075233459472656\n",
            "epochs:2.84 and loss:43.70306396484375\n",
            "epochs:2.85 and loss:43.33523178100586\n",
            "epochs:2.86 and loss:42.971763610839844\n",
            "epochs:2.87 and loss:42.61250686645508\n",
            "epochs:2.88 and loss:42.257469177246094\n",
            "epochs:2.89 and loss:41.9066047668457\n",
            "epochs:2.9 and loss:41.559818267822266\n",
            "epochs:2.91 and loss:41.21709060668945\n",
            "epochs:2.92 and loss:40.878360748291016\n",
            "epochs:2.93 and loss:40.5435905456543\n",
            "epochs:2.94 and loss:40.21271896362305\n",
            "epochs:2.95 and loss:39.885704040527344\n",
            "epochs:2.96 and loss:39.5625\n",
            "epochs:2.97 and loss:39.2430305480957\n",
            "epochs:2.98 and loss:38.927284240722656\n",
            "epochs:2.99 and loss:38.61518859863281\n",
            "epochs:3.0 and loss:38.30671310424805\n",
            "epochs:3.01 and loss:38.00183868408203\n",
            "epochs:3.02 and loss:37.700477600097656\n",
            "epochs:3.03 and loss:37.402587890625\n",
            "epochs:3.04 and loss:37.10814666748047\n",
            "epochs:3.05 and loss:36.81708526611328\n",
            "epochs:3.06 and loss:36.5294189453125\n",
            "epochs:3.07 and loss:36.24502182006836\n",
            "epochs:3.08 and loss:35.96392059326172\n",
            "epochs:3.09 and loss:35.686065673828125\n",
            "epochs:3.1 and loss:35.4113883972168\n",
            "epochs:3.11 and loss:35.139862060546875\n",
            "epochs:3.12 and loss:34.87144088745117\n",
            "epochs:3.13 and loss:34.606109619140625\n",
            "epochs:3.14 and loss:34.34381866455078\n",
            "epochs:3.15 and loss:34.08449172973633\n",
            "epochs:3.16 and loss:33.82819747924805\n",
            "epochs:3.17 and loss:33.574745178222656\n",
            "epochs:3.18 and loss:33.324241638183594\n",
            "epochs:3.19 and loss:33.07653045654297\n",
            "epochs:3.2 and loss:32.831703186035156\n",
            "epochs:3.21 and loss:32.5896110534668\n",
            "epochs:3.22 and loss:32.35026168823242\n",
            "epochs:3.23 and loss:32.113670349121094\n",
            "epochs:3.24 and loss:31.879718780517578\n",
            "epochs:3.25 and loss:31.648433685302734\n",
            "epochs:3.26 and loss:31.419750213623047\n",
            "epochs:3.27 and loss:31.193628311157227\n",
            "epochs:3.28 and loss:30.970081329345703\n",
            "epochs:3.29 and loss:30.749059677124023\n",
            "epochs:3.3 and loss:30.530506134033203\n",
            "epochs:3.31 and loss:30.314395904541016\n",
            "epochs:3.32 and loss:30.100727081298828\n",
            "epochs:3.33 and loss:29.889461517333984\n",
            "epochs:3.34 and loss:29.6805419921875\n",
            "epochs:3.35 and loss:29.473983764648438\n",
            "epochs:3.36 and loss:29.26970863342285\n",
            "epochs:3.37 and loss:29.067707061767578\n",
            "epochs:3.38 and loss:28.86798667907715\n",
            "epochs:3.39 and loss:28.670475006103516\n",
            "epochs:3.4 and loss:28.475143432617188\n",
            "epochs:3.41 and loss:28.281986236572266\n",
            "epochs:3.42 and loss:28.09098243713379\n",
            "epochs:3.43 and loss:27.902084350585938\n",
            "epochs:3.44 and loss:27.715251922607422\n",
            "epochs:3.45 and loss:27.530506134033203\n",
            "epochs:3.46 and loss:27.347789764404297\n",
            "epochs:3.47 and loss:27.167095184326172\n",
            "epochs:3.48 and loss:26.988361358642578\n",
            "epochs:3.49 and loss:26.811630249023438\n",
            "epochs:3.5 and loss:26.636821746826172\n",
            "epochs:3.51 and loss:26.463903427124023\n",
            "epochs:3.52 and loss:26.292898178100586\n",
            "epochs:3.53 and loss:26.123743057250977\n",
            "epochs:3.54 and loss:25.956436157226562\n",
            "epochs:3.55 and loss:25.790964126586914\n",
            "epochs:3.56 and loss:25.62728500366211\n",
            "epochs:3.57 and loss:25.465389251708984\n",
            "epochs:3.58 and loss:25.305240631103516\n",
            "epochs:3.59 and loss:25.146814346313477\n",
            "epochs:3.6 and loss:24.99013900756836\n",
            "epochs:3.61 and loss:24.835113525390625\n",
            "epochs:3.62 and loss:24.6817569732666\n",
            "epochs:3.63 and loss:24.53006935119629\n",
            "epochs:3.64 and loss:24.380027770996094\n",
            "epochs:3.65 and loss:24.2315731048584\n",
            "epochs:3.66 and loss:24.084692001342773\n",
            "epochs:3.67 and loss:23.939401626586914\n",
            "epochs:3.68 and loss:23.795642852783203\n",
            "epochs:3.69 and loss:23.65342140197754\n",
            "epochs:3.7 and loss:23.512720108032227\n",
            "epochs:3.71 and loss:23.373516082763672\n",
            "epochs:3.72 and loss:23.23580551147461\n",
            "epochs:3.73 and loss:23.09952163696289\n",
            "epochs:3.74 and loss:22.964689254760742\n",
            "epochs:3.75 and loss:22.831270217895508\n",
            "epochs:3.76 and loss:22.69925308227539\n",
            "epochs:3.77 and loss:22.568635940551758\n",
            "epochs:3.78 and loss:22.439382553100586\n",
            "epochs:3.79 and loss:22.31148338317871\n",
            "epochs:3.8 and loss:22.1849308013916\n",
            "epochs:3.81 and loss:22.059701919555664\n",
            "epochs:3.82 and loss:21.935733795166016\n",
            "epochs:3.83 and loss:21.8131046295166\n",
            "epochs:3.84 and loss:21.691707611083984\n",
            "epochs:3.85 and loss:21.57163429260254\n",
            "epochs:3.86 and loss:21.452739715576172\n",
            "epochs:3.87 and loss:21.335071563720703\n",
            "epochs:3.88 and loss:21.218645095825195\n",
            "epochs:3.89 and loss:21.103416442871094\n",
            "epochs:3.9 and loss:20.989351272583008\n",
            "epochs:3.91 and loss:20.876476287841797\n",
            "epochs:3.92 and loss:20.76473617553711\n",
            "epochs:3.93 and loss:20.654151916503906\n",
            "epochs:3.94 and loss:20.54466438293457\n",
            "epochs:3.95 and loss:20.436294555664062\n",
            "epochs:3.96 and loss:20.32902717590332\n",
            "epochs:3.97 and loss:20.222875595092773\n",
            "epochs:3.98 and loss:20.117767333984375\n",
            "epochs:3.99 and loss:20.01371192932129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds=model(inputs)\n",
        "loss=MSE(target,preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrMM0Yg_tqhX",
        "outputId": "2a700885-40a7-4545-9dd0-7c3d6fab4804"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(19.9107, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt\n",
        "print(sqrt(loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaoSzYTVuH1y",
        "outputId": "23e785f3-e856-4b53-9a65-1e974cf6f2c4"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.462144571462891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtHdqLbUuTF6",
        "outputId": "9fd9760f-bc8b-48ab-ff34-5f96413a1dd2"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 57.2099,  71.4850],\n",
              "        [ 85.1648,  99.2918],\n",
              "        [111.8961, 134.1999],\n",
              "        [ 20.9686,  44.5562],\n",
              "        [107.2675, 112.1517]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjgYGJYYuXvc",
        "outputId": "31846261-220e-4b47-8cf7-6c76c6639eb3"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.]])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_Xjpm8suaFD",
        "outputId": "99219868-7baa-49ba-9c48-a1f72044b486"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Apr 29 17:00:44 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8               9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor,Lambda,Compose\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "ijJ_ugwezS0-"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNK_4vnm0G7i",
        "outputId": "6988ca7a-a8e1-4d0d-c11f-1e1e5631e938"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 26421880/26421880 [00:01<00:00, 16215706.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 29515/29515 [00:00<00:00, 274651.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 4422102/4422102 [00:00<00:00, 5109299.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 5148/5148 [00:00<00:00, 4984366.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(training_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "QJ6RJiMW1CDY",
        "outputId": "54cb4a89-bd94-44e1-f653-39fb5edb2533"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchvision.datasets.mnist.FashionMNIST"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torchvision.datasets.mnist.FashionMNIST</b><br/>def __init__(root: str, train: bool=True, transform: Optional[Callable]=None, target_transform: Optional[Callable]=None, download: bool=False) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py</a>`Fashion-MNIST &lt;https://github.com/zalandoresearch/fashion-mnist&gt;`_ Dataset.\n",
              "\n",
              "Args:\n",
              "    root (string): Root directory of dataset where ``FashionMNIST/raw/train-images-idx3-ubyte``\n",
              "        and  ``FashionMNIST/raw/t10k-images-idx3-ubyte`` exist.\n",
              "    train (bool, optional): If True, creates dataset from ``train-images-idx3-ubyte``,\n",
              "        otherwise from ``t10k-images-idx3-ubyte``.\n",
              "    download (bool, optional): If True, downloads the dataset from the internet and\n",
              "        puts it in root directory. If dataset is already downloaded, it is not\n",
              "        downloaded again.\n",
              "    transform (callable, optional): A function/transform that  takes in an PIL image\n",
              "        and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
              "    target_transform (callable, optional): A function/transform that takes in the\n",
              "        target and transforms it.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 202);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=64\n",
        "\n",
        "train_dataloader = DataLoader(training_data,batch_size)\n",
        "test_dataloader = DataLoader(test_data,batch_size)\n",
        "\n",
        "for x,y in test_dataloader:\n",
        "  print(\"Shape of X[N,C,H,W]:\",x.shape)\n",
        "  print(\"shape of y\",y.shape,y.dtype)\n",
        "  print(x)\n",
        "  print(y)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rhh_K99-1nkc",
        "outputId": "bd44cf2d-9383-4d5e-c8de-76b93b2fd420"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X[N,C,H,W]: torch.Size([64, 1, 28, 28])\n",
            "shape of y torch.Size([64]) torch.int64\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
            "tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 7, 3, 4, 1, 2, 4, 8, 0, 2, 5, 7, 9,\n",
            "        1, 4, 6, 0, 9, 3, 8, 8, 3, 3, 8, 0, 7, 5, 7, 9, 6, 1, 3, 7, 6, 7, 2, 1,\n",
            "        2, 2, 4, 4, 5, 8, 2, 2, 8, 4, 8, 0, 7, 7, 8, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"device:{device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RVHbeZ_22TD",
        "outputId": "3e440f74-773c-4824-e686-1456ef0f2916"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device:cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork,self).__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,10)\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmI7eTcA3Y5f",
        "outputId": "249d19ce-dd5b-41a2-8eaf-5a2cd9f79b76"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=1e-3)"
      ],
      "metadata": {
        "id": "SIZ89cIi6GaP"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader,model,loss_fn,optimizer):\n",
        "  size=len(dataloader.dataset)\n",
        "  model.train()\n",
        "  for batch,(X,y) in enumerate(dataloader):\n",
        "    X,y = X.to(device),y.to(device)\n",
        "\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred,y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss,current = loss.item(), batch*len(X)\n",
        "      print(f\"loss:{loss:>7f} [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "yDV1dGk47jJR"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader,model,loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "      for X, y in dataloader:\n",
        "          X, y = X.to(device), y.to(device)\n",
        "          pred = model(X)\n",
        "          test_loss += loss_fn(pred, y).item()\n",
        "          correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "wMnQnGnl-FxC"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvsAPtQ6-vuN",
        "outputId": "b1edd8a2-d69d-43c0-c9fc-8b43372eba46"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss:2.303403 [    0/60000]\n",
            "loss:2.291225 [ 6400/60000]\n",
            "loss:2.273651 [12800/60000]\n",
            "loss:2.263516 [19200/60000]\n",
            "loss:2.257194 [25600/60000]\n",
            "loss:2.223367 [32000/60000]\n",
            "loss:2.235227 [38400/60000]\n",
            "loss:2.200183 [44800/60000]\n",
            "loss:2.201983 [51200/60000]\n",
            "loss:2.174620 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 44.5%, Avg loss: 2.166714 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss:2.177829 [    0/60000]\n",
            "loss:2.170161 [ 6400/60000]\n",
            "loss:2.117217 [12800/60000]\n",
            "loss:2.128741 [19200/60000]\n",
            "loss:2.084393 [25600/60000]\n",
            "loss:2.030281 [32000/60000]\n",
            "loss:2.060918 [38400/60000]\n",
            "loss:1.982730 [44800/60000]\n",
            "loss:1.996381 [51200/60000]\n",
            "loss:1.937062 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 52.3%, Avg loss: 1.922513 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss:1.951904 [    0/60000]\n",
            "loss:1.924667 [ 6400/60000]\n",
            "loss:1.815968 [12800/60000]\n",
            "loss:1.853741 [19200/60000]\n",
            "loss:1.741420 [25600/60000]\n",
            "loss:1.699743 [32000/60000]\n",
            "loss:1.725519 [38400/60000]\n",
            "loss:1.617359 [44800/60000]\n",
            "loss:1.650533 [51200/60000]\n",
            "loss:1.556882 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 59.0%, Avg loss: 1.558140 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss:1.617519 [    0/60000]\n",
            "loss:1.584261 [ 6400/60000]\n",
            "loss:1.440136 [12800/60000]\n",
            "loss:1.508791 [19200/60000]\n",
            "loss:1.385917 [25600/60000]\n",
            "loss:1.380270 [32000/60000]\n",
            "loss:1.395263 [38400/60000]\n",
            "loss:1.312780 [44800/60000]\n",
            "loss:1.352864 [51200/60000]\n",
            "loss:1.252341 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 63.6%, Avg loss: 1.276749 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss:1.348216 [    0/60000]\n",
            "loss:1.329213 [ 6400/60000]\n",
            "loss:1.175819 [12800/60000]\n",
            "loss:1.270850 [19200/60000]\n",
            "loss:1.149737 [25600/60000]\n",
            "loss:1.171988 [32000/60000]\n",
            "loss:1.187039 [38400/60000]\n",
            "loss:1.123575 [44800/60000]\n",
            "loss:1.168198 [51200/60000]\n",
            "loss:1.074535 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.9%, Avg loss: 1.100406 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save model\n",
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wj65yIX-7YN",
        "outputId": "1ea5a029-b179-45b4-c7fc-b421d82d89d4"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork()\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCzIUZunAc0_",
        "outputId": "53c6ce3a-8354-4257-85e7-92e9d059400b"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wERQe_2AjT4",
        "outputId": "e128eddf-cfea-4d44-c144-3f8a2a8fe3e7"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5bBq9gVFApCZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}